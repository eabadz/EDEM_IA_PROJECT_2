{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IA PROJECT 2: LOAN APPROVAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loan Dataset Features\n",
    "\n",
    "| Variable                         | Description                                                                                 | Data Type     |\n",
    "|----------------------------------|---------------------------------------------------------------------------------------------|---------------|\n",
    "| `person_age`                     | Person's age                                                                                | Float         |\n",
    "| `person_gender`                  | Person's gender                                                                             | Categorical   |\n",
    "| `person_education`              | Highest education level                                                                     | Categorical   |\n",
    "| `person_income`                  | Annual income                                                                              | Float         |\n",
    "| `person_emp_exp`                 | Years of work experience                                                                   | Integer       |\n",
    "| `person_home_ownership`          | Home ownership status (e.g., rent, own, mortgage)                                          | Categorical   |\n",
    "| `loan_amnt`                      | Requested loan amount                                                                      | Float         |\n",
    "| `loan_intent`                    | Loan purpose                                                                               | Categorical   |\n",
    "| `loan_int_rate`                  | Loan interest rate                                                                         | Float         |\n",
    "| `loan_percent_income`            | Loan amount as a percentage of annual income                                               | Float         |\n",
    "| `cb_person_cred_hist_length`     | Length of credit history in years                                                          | Float         |\n",
    "| `credit_score`                   | Person's credit score (The higher the score, the lower the assumed risk of default)        | Integer       |\n",
    "| `previous_loan_defaults_on_file` | Indicator of previous loan defaults                                                        | Categorical   |\n",
    "| `loan_status` (label)           | Loan approval status: 1 = approved; 0 = rejected                                            | Integer       |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this dataset, we can address both a regression problem—predicting the `credit_score` —and a classification problem using the `loan_status` feature to determine whether the loan will be approved or not.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pepeb\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\seaborn\\__init__.py:5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpalettes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrelational\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregression\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcategorical\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m  \u001b[38;5;66;03m# noqa: F401,F403\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pepeb\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\seaborn\\relational.py:21\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     14\u001b[0m     adjust_legend_subtitles,\n\u001b[0;32m     15\u001b[0m     _default_color,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m     _scatter_legend_artist,\n\u001b[0;32m     19\u001b[0m )\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_compat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m groupby_apply_include_groups\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_statistics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EstimateAggregator, WeightedAggregator\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maxisgrid\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FacetGrid, _facet_docs\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_docstrings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DocstringComponents, _core_docs\n",
      "File \u001b[1;32mc:\\Users\\pepeb\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\seaborn\\_statistics.py:32\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 32\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gaussian_kde\n\u001b[0;32m     33\u001b[0m     _no_scipy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\pepeb\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\stats\\__init__.py:624\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03m.. _statsrefmanual:\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    619\u001b[0m \n\u001b[0;32m    620\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_warnings_errors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (ConstantInputWarning, NearConstantInputWarning,\n\u001b[0;32m    623\u001b[0m                                DegenerateDataWarning, FitError)\n\u001b[1;32m--> 624\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_stats_py\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_variation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m variation\n\u001b[0;32m    626\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\pepeb\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\stats\\_stats_py.py:38\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m array, asarray, ma\n\u001b[1;32m---> 38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sparse\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspatial\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distance_matrix\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m milp, LinearConstraint\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1412\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\pepeb\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\__init__.py:146\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(name):\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m submodules:\n\u001b[1;32m--> 146\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_importlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mscipy.\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    147\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    148\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\pepeb\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\importlib\\__init__.py:90\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     89\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\pepeb\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\sparse\\__init__.py:315\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_sputils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_index_dtype, safely_cast_index_arrays\n\u001b[0;32m    314\u001b[0m \u001b[38;5;66;03m# For backward compatibility with v0.19.\u001b[39;00m\n\u001b[1;32m--> 315\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m csgraph\n\u001b[0;32m    317\u001b[0m \u001b[38;5;66;03m# Deprecated namespaces, to be removed in v2.0.0\u001b[39;00m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    319\u001b[0m     base, bsr, compressed, construct, coo, csc, csr, data, dia, dok, extract,\n\u001b[0;32m    320\u001b[0m     lil, sparsetools, sputils\n\u001b[0;32m    321\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\pepeb\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\sparse\\csgraph\\__init__.py:187\u001b[0m\n\u001b[0;32m    158\u001b[0m __docformat__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrestructuredtext en\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconnected_components\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    161\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlaplacian\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    162\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshortest_path\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    184\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcsgraph_to_masked\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    185\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNegativeCycleError\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m--> 187\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_laplacian\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m laplacian\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_shortest_path\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    189\u001b[0m     shortest_path, floyd_warshall, dijkstra, bellman_ford, johnson, yen,\n\u001b[0;32m    190\u001b[0m     NegativeCycleError\n\u001b[0;32m    191\u001b[0m )\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_traversal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    193\u001b[0m     breadth_first_order, depth_first_order, breadth_first_tree,\n\u001b[0;32m    194\u001b[0m     depth_first_tree, connected_components\n\u001b[0;32m    195\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\pepeb\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\sparse\\csgraph\\_laplacian.py:7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m issparse\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearOperator\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_sputils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m convert_pydata_sparse_to_scipy, is_pydata_spmatrix\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m###############################################################################\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Graph laplacian\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\pepeb\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\sparse\\linalg\\__init__.py:129\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mSparse linear algebra (:mod:`scipy.sparse.linalg`)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m==================================================\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    126\u001b[0m \n\u001b[0;32m    127\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 129\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_isolve\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dsolve\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_interface\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\pepeb\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\sparse\\linalg\\_isolve\\__init__.py:4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIterative Solvers for Sparse Linear Systems\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#from info import __doc__\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01miterative\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mminres\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m minres\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlgmres\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lgmres\n",
      "File \u001b[1;32mc:\\Users\\pepeb\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\sparse\\linalg\\_isolve\\iterative.py:5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_interface\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearOperator\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m make_system\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_lapack_funcs\n\u001b[0;32m      7\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbicg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbicgstab\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcg\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcgs\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgmres\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mqmr\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_atol_rtol\u001b[39m(name, b_norm, atol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.\u001b[39m, rtol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-5\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\pepeb\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\linalg\\__init__.py:203\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03m====================================\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mLinear algebra (:mod:`scipy.linalg`)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    200\u001b[0m \n\u001b[0;32m    201\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[1;32m--> 203\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_misc\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_cythonized_array_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_basic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\pepeb\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\linalg\\_misc.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinAlgError\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mblas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_blas_funcs\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlapack\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_lapack_funcs\n\u001b[0;32m      6\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLinAlgError\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLinAlgWarning\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnorm\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\pepeb\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\scipy\\linalg\\blas.py:213\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mfunctools\u001b[39;00m\n\u001b[1;32m--> 213\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _fblas\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _cblas\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_age</th>\n",
       "      <th>person_gender</th>\n",
       "      <th>person_education</th>\n",
       "      <th>person_income</th>\n",
       "      <th>person_emp_exp</th>\n",
       "      <th>person_home_ownership</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>loan_intent</th>\n",
       "      <th>loan_int_rate</th>\n",
       "      <th>loan_percent_income</th>\n",
       "      <th>cb_person_cred_hist_length</th>\n",
       "      <th>credit_score</th>\n",
       "      <th>previous_loan_defaults_on_file</th>\n",
       "      <th>loan_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>female</td>\n",
       "      <td>Master</td>\n",
       "      <td>71948.0</td>\n",
       "      <td>0</td>\n",
       "      <td>RENT</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>PERSONAL</td>\n",
       "      <td>16.02</td>\n",
       "      <td>0.49</td>\n",
       "      <td>3.0</td>\n",
       "      <td>561</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.0</td>\n",
       "      <td>female</td>\n",
       "      <td>High School</td>\n",
       "      <td>12282.0</td>\n",
       "      <td>0</td>\n",
       "      <td>OWN</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>EDUCATION</td>\n",
       "      <td>11.14</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>504</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.0</td>\n",
       "      <td>female</td>\n",
       "      <td>High School</td>\n",
       "      <td>12438.0</td>\n",
       "      <td>3</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>MEDICAL</td>\n",
       "      <td>12.87</td>\n",
       "      <td>0.44</td>\n",
       "      <td>3.0</td>\n",
       "      <td>635</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.0</td>\n",
       "      <td>female</td>\n",
       "      <td>Bachelor</td>\n",
       "      <td>79753.0</td>\n",
       "      <td>0</td>\n",
       "      <td>RENT</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>MEDICAL</td>\n",
       "      <td>15.23</td>\n",
       "      <td>0.44</td>\n",
       "      <td>2.0</td>\n",
       "      <td>675</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.0</td>\n",
       "      <td>male</td>\n",
       "      <td>Master</td>\n",
       "      <td>66135.0</td>\n",
       "      <td>1</td>\n",
       "      <td>RENT</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>MEDICAL</td>\n",
       "      <td>14.27</td>\n",
       "      <td>0.53</td>\n",
       "      <td>4.0</td>\n",
       "      <td>586</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   person_age person_gender person_education  person_income  person_emp_exp  \\\n",
       "0        22.0        female           Master        71948.0               0   \n",
       "1        21.0        female      High School        12282.0               0   \n",
       "2        25.0        female      High School        12438.0               3   \n",
       "3        23.0        female         Bachelor        79753.0               0   \n",
       "4        24.0          male           Master        66135.0               1   \n",
       "\n",
       "  person_home_ownership  loan_amnt loan_intent  loan_int_rate  \\\n",
       "0                  RENT    35000.0    PERSONAL          16.02   \n",
       "1                   OWN     1000.0   EDUCATION          11.14   \n",
       "2              MORTGAGE     5500.0     MEDICAL          12.87   \n",
       "3                  RENT    35000.0     MEDICAL          15.23   \n",
       "4                  RENT    35000.0     MEDICAL          14.27   \n",
       "\n",
       "   loan_percent_income  cb_person_cred_hist_length  credit_score  \\\n",
       "0                 0.49                         3.0           561   \n",
       "1                 0.08                         2.0           504   \n",
       "2                 0.44                         3.0           635   \n",
       "3                 0.44                         2.0           675   \n",
       "4                 0.53                         4.0           586   \n",
       "\n",
       "  previous_loan_defaults_on_file  loan_status  \n",
       "0                             No            1  \n",
       "1                            Yes            0  \n",
       "2                             No            1  \n",
       "3                             No            1  \n",
       "4                             No            1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Dataset\n",
    "df = pd.read_csv('dataset.csv')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 45000 entries, 0 to 44999\n",
      "Data columns (total 14 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   person_age                      45000 non-null  float64\n",
      " 1   person_gender                   45000 non-null  object \n",
      " 2   person_education                45000 non-null  object \n",
      " 3   person_income                   45000 non-null  float64\n",
      " 4   person_emp_exp                  45000 non-null  int64  \n",
      " 5   person_home_ownership           45000 non-null  object \n",
      " 6   loan_amnt                       45000 non-null  float64\n",
      " 7   loan_intent                     45000 non-null  object \n",
      " 8   loan_int_rate                   45000 non-null  float64\n",
      " 9   loan_percent_income             45000 non-null  float64\n",
      " 10  cb_person_cred_hist_length      45000 non-null  float64\n",
      " 11  credit_score                    45000 non-null  int64  \n",
      " 12  previous_loan_defaults_on_file  45000 non-null  object \n",
      " 13  loan_status                     45000 non-null  int64  \n",
      "dtypes: float64(6), int64(3), object(5)\n",
      "memory usage: 4.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No nulls in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_age</th>\n",
       "      <th>person_income</th>\n",
       "      <th>person_emp_exp</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>loan_int_rate</th>\n",
       "      <th>loan_percent_income</th>\n",
       "      <th>cb_person_cred_hist_length</th>\n",
       "      <th>credit_score</th>\n",
       "      <th>loan_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>45000.000000</td>\n",
       "      <td>4.500000e+04</td>\n",
       "      <td>45000.000000</td>\n",
       "      <td>45000.000000</td>\n",
       "      <td>45000.000000</td>\n",
       "      <td>45000.000000</td>\n",
       "      <td>45000.000000</td>\n",
       "      <td>45000.000000</td>\n",
       "      <td>45000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>27.764178</td>\n",
       "      <td>8.031905e+04</td>\n",
       "      <td>5.410333</td>\n",
       "      <td>9583.157556</td>\n",
       "      <td>11.006606</td>\n",
       "      <td>0.139725</td>\n",
       "      <td>5.867489</td>\n",
       "      <td>632.608756</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.045108</td>\n",
       "      <td>8.042250e+04</td>\n",
       "      <td>6.063532</td>\n",
       "      <td>6314.886691</td>\n",
       "      <td>2.978808</td>\n",
       "      <td>0.087212</td>\n",
       "      <td>3.879702</td>\n",
       "      <td>50.435865</td>\n",
       "      <td>0.415744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>8.000000e+03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>5.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>390.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>4.720400e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5000.000000</td>\n",
       "      <td>8.590000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>601.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>26.000000</td>\n",
       "      <td>6.704800e+04</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8000.000000</td>\n",
       "      <td>11.010000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>640.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>30.000000</td>\n",
       "      <td>9.578925e+04</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>12237.250000</td>\n",
       "      <td>12.990000</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>670.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>144.000000</td>\n",
       "      <td>7.200766e+06</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>35000.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>850.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         person_age  person_income  person_emp_exp     loan_amnt  \\\n",
       "count  45000.000000   4.500000e+04    45000.000000  45000.000000   \n",
       "mean      27.764178   8.031905e+04        5.410333   9583.157556   \n",
       "std        6.045108   8.042250e+04        6.063532   6314.886691   \n",
       "min       20.000000   8.000000e+03        0.000000    500.000000   \n",
       "25%       24.000000   4.720400e+04        1.000000   5000.000000   \n",
       "50%       26.000000   6.704800e+04        4.000000   8000.000000   \n",
       "75%       30.000000   9.578925e+04        8.000000  12237.250000   \n",
       "max      144.000000   7.200766e+06      125.000000  35000.000000   \n",
       "\n",
       "       loan_int_rate  loan_percent_income  cb_person_cred_hist_length  \\\n",
       "count   45000.000000         45000.000000                45000.000000   \n",
       "mean       11.006606             0.139725                    5.867489   \n",
       "std         2.978808             0.087212                    3.879702   \n",
       "min         5.420000             0.000000                    2.000000   \n",
       "25%         8.590000             0.070000                    3.000000   \n",
       "50%        11.010000             0.120000                    4.000000   \n",
       "75%        12.990000             0.190000                    8.000000   \n",
       "max        20.000000             0.660000                   30.000000   \n",
       "\n",
       "       credit_score   loan_status  \n",
       "count  45000.000000  45000.000000  \n",
       "mean     632.608756      0.222222  \n",
       "std       50.435865      0.415744  \n",
       "min      390.000000      0.000000  \n",
       "25%      601.000000      0.000000  \n",
       "50%      640.000000      0.000000  \n",
       "75%      670.000000      0.000000  \n",
       "max      850.000000      1.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['loan_status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be observed that the label in our dataset is imbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select numeric columns, excluding 'loan_status'\n",
    "numeric_cols = [col for col in df.select_dtypes(include=['number']).columns if col != 'loan_status']\n",
    "\n",
    "# 1. Boxplots for numeric variables (excluding 'loan_status')\n",
    "for col in numeric_cols:\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    sns.boxplot(y=df[col])\n",
    "    plt.title(f\"Boxplot of {col}\")\n",
    "    plt.show()\n",
    "\n",
    "# 2. Bar charts for categorical variables\n",
    "categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "for col in categorical_cols:\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    df[col].value_counts().plot(kind='bar')\n",
    "    plt.title(f\"Frequency of {col}\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BASIC ANN MODEL WITHOUT CLEANING DATASET (ONLY NaNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchsummary import summary\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x29d1b0e1850>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set random seed for reproducibility\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "\n",
    "# 'loan_status' is the target column\n",
    "y = df[\"loan_status\"]\n",
    "X = df.drop([\"loan_status\"], axis=1)\n",
    "\n",
    "# Encode categorical columns \n",
    "categorical_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col].astype(str))\n",
    "\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X = X.values\n",
    "y = y.values\n",
    "\n",
    "# Split the data into train, val, and test\n",
    "\n",
    "# First split: test = 20%, train_val = 80%\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Second split: of the remaining 80%, 10% goes to val => 90% train, 10% val\n",
    "# (10% of 80% is 8% total)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, \n",
    "    y_train_val,\n",
    "    test_size=0.1,   # 10% of the remaining 80%\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# 4. Convert numpy arrays to PyTorch tensors\n",
    "\n",
    "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_t = torch.tensor(y_train, dtype=torch.float32)\n",
    "\n",
    "X_val_t = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_t = torch.tensor(y_val, dtype=torch.float32)\n",
    "\n",
    "X_test_t = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_t = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "\n",
    "# 5. Create TensorDatasets and DataLoaders\n",
    "\n",
    "train_dataset = TensorDataset(X_train_t, y_train_t)\n",
    "val_dataset   = TensorDataset(X_val_t, y_val_t)\n",
    "test_dataset  = TensorDataset(X_test_t, y_test_t)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_t[0], y_train_t[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoanApprovalANN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(LoanApprovalANN, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),  # First hidden layer (input -> 64)\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),  # Second hidden layer (64 -> 32)\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,32),  # Output layer (32 -> 1)\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32,1),  # Output layer (32 -> 1)\n",
    "            nn.Sigmoid()  # Activation for binary classification\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = X_train_t.shape[1]  # Number of features\n",
    "model = LoanApprovalANN(input_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model summary\n",
    "summary(model, (input_size,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Define loss function\n",
    "criterion = nn.BCELoss()  # Binary Cross Entropy Loss\n",
    "\n",
    "# Define optimizer (Adam)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Define device (GPU if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Store training history\n",
    "train_loss_history = []\n",
    "valid_loss_history = []\n",
    "train_accuracy_history = []\n",
    "valid_accuracy_history = []\n",
    "\n",
    "# Number of epochs\n",
    "num_epochs = 25\n",
    "\n",
    "def get_accuracy(preds, labels):\n",
    "    \"\"\"Calculate accuracy given model predictions and actual labels.\"\"\"\n",
    "    preds = (preds >= 0.5).float()  # Convert to binary values (0 or 1)\n",
    "    return (preds == labels).sum().item() / labels.size(0)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    for i, (X_batch, y_batch) in enumerate(train_loader):\n",
    "\n",
    "        # Move data to device\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        y_pred = model(X_batch).squeeze()\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "\n",
    "    # Calculate accuracy & loss for training and validation\n",
    "    train_loss = 0\n",
    "    valid_loss = 0\n",
    "    train_accuracy = 0\n",
    "    valid_accuracy = 0\n",
    "\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            y_pred = model(X_batch).squeeze()\n",
    "            train_loss += criterion(y_pred, y_batch).item()\n",
    "            train_accuracy += get_accuracy(y_pred, y_batch)\n",
    "\n",
    "        train_loss_history.append(train_loss / len(train_loader))\n",
    "        train_accuracy_history.append(train_accuracy / len(train_loader))\n",
    "\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            y_pred = model(X_batch).squeeze()\n",
    "            valid_loss += criterion(y_pred, y_batch).item()\n",
    "            valid_accuracy += get_accuracy(y_pred, y_batch)\n",
    "\n",
    "        valid_loss_history.append(valid_loss / len(val_loader))\n",
    "        valid_accuracy_history.append(valid_accuracy / len(val_loader))\n",
    "\n",
    "    # Print epoch summary\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | \"\n",
    "          f\"Train loss: {train_loss/len(train_loader):.3f} | \"\n",
    "          f\"Train accuracy: {train_accuracy/len(train_loader):.3f} | \"\n",
    "          f\"Valid loss: {valid_loss/len(val_loader):.3f} | \"\n",
    "          f\"Valid accuracy: {valid_accuracy/len(val_loader):.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation accuracy\n",
    "plt.plot(train_accuracy_history)\n",
    "plt.plot(valid_accuracy_history)\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation accuracy\n",
    "plt.plot(train_loss_history)\n",
    "plt.plot(valid_loss_history)\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Initialize variables for metrics\n",
    "test_loss = 0.0\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "# No need to track gradients during evaluation\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        y_pred = model(X_batch).squeeze()\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        # Convert predictions to binary (0 or 1)\n",
    "        predicted = (y_pred >= 0.5).float()\n",
    "\n",
    "        # Store predictions and labels for metrics calculation\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(y_batch.cpu().numpy())\n",
    "\n",
    "# Compute average test loss\n",
    "avg_test_loss = test_loss / len(test_loader)\n",
    "\n",
    "# Compute classification metrics\n",
    "test_accuracy = accuracy_score(all_labels, all_preds)\n",
    "test_precision = precision_score(all_labels, all_preds)\n",
    "test_recall = recall_score(all_labels, all_preds)\n",
    "test_f1 = f1_score(all_labels, all_preds)\n",
    "\n",
    "# Print results\n",
    "print(f\"Test Loss: {avg_test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Precision: {test_precision:.4f}\")\n",
    "print(f\"Test Recall: {test_recall:.4f}\")\n",
    "print(f\"Test F1 Score: {test_f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREGUNTAR POR QUE OSCILA TANTO LA GRAFICA DE LA PRECISION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation between features and label\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Convert categorical columns to numeric using LabelEncoder\n",
    "categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "le = LabelEncoder()\n",
    "\n",
    "for col in categorical_cols:\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "\n",
    "# Compute correlation matrix again\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "# Extract correlation of each feature with 'loan_status'\n",
    "correlation_with_target = correlation_matrix[\"loan_status\"].drop(\"loan_status\")\n",
    "\n",
    "# Sort by absolute correlation value\n",
    "correlation_with_target = correlation_with_target.abs().sort_values(ascending=False)\n",
    "\n",
    "# Plot correlation as a bar chart\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(x=correlation_with_target.values, y=correlation_with_target.index, palette=\"Blues\")\n",
    "plt.xlabel(\"Correlation with Loan Status\")\n",
    "plt.ylabel(\"Features\")\n",
    "plt.title(\"Feature Correlation with Loan Status\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BarChar comparing categorical features with label\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# Plot bar charts for each categorical variable grouped by 'loan_status'\n",
    "for col in categorical_cols:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.countplot(x=df[col], hue=df[\"loan_status\"], palette=\"Blues\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.title(f\"Distribution of {col} by Loan Status\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend(title=\"Loan Status\", labels=[\"Rejected (0)\", \"Approved (1)\"])\n",
    "    plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify categorical columns\n",
    "categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "# Create a dictionary to store proportions\n",
    "category_proportions = {}\n",
    "\n",
    "# Calculate proportions for each categorical variable\n",
    "for col in categorical_cols:\n",
    "    proportion_df = df.groupby([col, \"loan_status\"]).size().unstack(fill_value=0)  # Ensure all categories are included\n",
    "    proportion_df = proportion_df.div(proportion_df.sum(axis=1), axis=0)  # Normalize to get proportions\n",
    "    category_proportions[col] = proportion_df\n",
    "\n",
    "# Display the proportions\n",
    "for col, prop_df in category_proportions.items():\n",
    "    print(f\"Proportions of {col} by Loan Status:\")\n",
    "    print(prop_df)\n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "* Gender, person_education, loan_intent aren´t important\n",
    "* If you have a mortage or your own house is not probable to be given a loan\n",
    "* If you have previous loan you wont get a loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify numerical columns (excluding 'loan_status')\n",
    "numerical_cols = df.select_dtypes(include=['number']).columns.drop(\"loan_status\")\n",
    "\n",
    "# Create boxplots for each numerical variable grouped by 'loan_status'\n",
    "for col in numerical_cols:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.boxplot(x=df[\"loan_status\"], y=df[col], palette=\"Blues\")\n",
    "    plt.xlabel(\"Loan Status\")\n",
    "    plt.ylabel(col)\n",
    "    plt.title(f\"Boxplot of {col} by Loan Status\")\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "* +80 age wont get a loan\n",
    "* +1,2 income wont get a loan\n",
    "* +55 years_experience wont get a loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns that aren´t relevant\n",
    "df.drop(columns=[\"person_gender\", \"person_education\", \"loan_intent\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply one-hot encoding in 'person_home_ownership'\n",
    "df = pd.get_dummies(df, columns=[\"person_home_ownership\"], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change  Yes/No \"previous_loan_defaults_on_file\" columm to 1/0\n",
    "\n",
    "# Ensure the column is numeric\n",
    "df[\"previous_loan_defaults_on_file\"] = df[\"previous_loan_defaults_on_file\"].astype(str)\n",
    "\n",
    "# Convert any non-zero or non-null value to 1\n",
    "df[\"had_previous_loans\"] = df[\"previous_loan_defaults_on_file\"].apply(lambda x: 1 if x != \"0\" and x.lower() != \"nan\" else 0)\n",
    "\n",
    "# Drop the original column\n",
    "df.drop(columns=[\"previous_loan_defaults_on_file\"], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary features (Not sure if it will improve the model accuracy and precision)\n",
    "df[\"age_80_plus\"] = (df[\"person_age\"] > 80).astype(int)\n",
    "df[\"high_income\"] = (df[\"person_income\"] > 1.2e6).astype(int)\n",
    "df[\"exp_55_plus\"] = (df[\"person_emp_exp\"] > 55).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANN MODEL WITH EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "\n",
    "# 'loan_status' is the target column\n",
    "y = df[\"loan_status\"]\n",
    "X = df.drop([\"loan_status\"], axis=1)\n",
    "\n",
    "# Encode categorical columns \n",
    "# categorical_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "# for col in categorical_cols:\n",
    "#     le = LabelEncoder()\n",
    "#     X[col] = le.fit_transform(X[col].astype(str))\n",
    "\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X = X.values\n",
    "y = y.values\n",
    "\n",
    "# Split the data into train, val, and test\n",
    "\n",
    "# First split: test = 20%, train_val = 80%\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Second split: of the remaining 80%, 10% goes to val => 90% train, 10% val\n",
    "# (10% of 80% is 8% total)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_val, \n",
    "    y_train_val,\n",
    "    test_size=0.1,   # 10% of the remaining 80%\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# 4. Convert numpy arrays to PyTorch tensors\n",
    "\n",
    "X_train_t = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_t = torch.tensor(y_train, dtype=torch.float32)\n",
    "\n",
    "X_val_t = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val_t = torch.tensor(y_val, dtype=torch.float32)\n",
    "\n",
    "X_test_t = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_t = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "\n",
    "# 5. Create TensorDatasets and DataLoaders\n",
    "\n",
    "train_dataset = TensorDataset(X_train_t, y_train_t)\n",
    "val_dataset   = TensorDataset(X_val_t, y_val_t)\n",
    "test_dataset  = TensorDataset(X_test_t, y_test_t)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LoanApprovalANN(nn.Module):\n",
    "#     def __init__(self, input_size):\n",
    "#         super(LoanApprovalANN, self).__init__()\n",
    "        \n",
    "#         self.model = nn.Sequential(\n",
    "#             nn.Linear(input_size, 128),  # First hidden layer (input -> 64)\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(128, 64),  # Second hidden layer (64 -> 32)\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(64,32),  # Output layer (32 -> 1)\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(32,1),  # Output layer (32 -> 1)\n",
    "#             nn.Sigmoid()  # Activation for binary classification\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.model(x)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LoanApprovalANN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(LoanApprovalANN, self).__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, 256),  # Primera capa oculta (input → 256 neuronas)\n",
    "            nn.BatchNorm1d(256),  # Normalización para estabilizar el entrenamiento\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),  # Apaga el 30% de las neuronas en cada forward pass\n",
    "            \n",
    "            nn.Linear(256, 128),  # Segunda capa oculta (256 → 128 neuronas)\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(128, 64),  # Tercera capa oculta (128 → 64 neuronas)\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "\n",
    "            nn.Linear(64, 32),  # Cuarta capa oculta (64 → 32 neuronas)\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Linear(32, 1),  # Capa de salida (32 → 1 neurona)\n",
    "            nn.Sigmoid()  # Activación Sigmoid para clasificación binaria\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = X_train_t.shape[1]  # Number of features\n",
    "model = LoanApprovalANN(input_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                  [-1, 256]           4,096\n",
      "       BatchNorm1d-2                  [-1, 256]             512\n",
      "              ReLU-3                  [-1, 256]               0\n",
      "           Dropout-4                  [-1, 256]               0\n",
      "            Linear-5                  [-1, 128]          32,896\n",
      "       BatchNorm1d-6                  [-1, 128]             256\n",
      "              ReLU-7                  [-1, 128]               0\n",
      "           Dropout-8                  [-1, 128]               0\n",
      "            Linear-9                   [-1, 64]           8,256\n",
      "      BatchNorm1d-10                   [-1, 64]             128\n",
      "             ReLU-11                   [-1, 64]               0\n",
      "          Dropout-12                   [-1, 64]               0\n",
      "           Linear-13                   [-1, 32]           2,080\n",
      "             ReLU-14                   [-1, 32]               0\n",
      "           Linear-15                    [-1, 1]              33\n",
      "          Sigmoid-16                    [-1, 1]               0\n",
      "================================================================\n",
      "Total params: 48,257\n",
      "Trainable params: 48,257\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.01\n",
      "Params size (MB): 0.18\n",
      "Estimated Total Size (MB): 0.20\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Model summary\n",
    "summary(model, (input_size,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LoanApprovalANN(\n",
       "  (model): Sequential(\n",
       "    (0): Linear(in_features=15, out_features=256, bias=True)\n",
       "    (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.3, inplace=False)\n",
       "    (4): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (5): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (6): ReLU()\n",
       "    (7): Dropout(p=0.3, inplace=False)\n",
       "    (8): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (9): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (10): ReLU()\n",
       "    (11): Dropout(p=0.2, inplace=False)\n",
       "    (12): Linear(in_features=64, out_features=32, bias=True)\n",
       "    (13): ReLU()\n",
       "    (14): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (15): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Define loss function\n",
    "criterion = nn.BCELoss()  # Binary Cross Entropy Loss\n",
    "\n",
    "# Define optimizer (Adam)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25 | Train loss: 0.317 | Train accuracy: 0.867 | Valid loss: 0.329 | Valid accuracy: 0.860\n",
      "Epoch 2/25 | Train loss: 0.307 | Train accuracy: 0.877 | Valid loss: 0.316 | Valid accuracy: 0.873\n",
      "Epoch 3/25 | Train loss: 0.309 | Train accuracy: 0.880 | Valid loss: 0.317 | Valid accuracy: 0.873\n",
      "Epoch 4/25 | Train loss: 0.314 | Train accuracy: 0.875 | Valid loss: 0.322 | Valid accuracy: 0.873\n",
      "Epoch 5/25 | Train loss: 0.301 | Train accuracy: 0.881 | Valid loss: 0.312 | Valid accuracy: 0.875\n",
      "Epoch 6/25 | Train loss: 0.301 | Train accuracy: 0.881 | Valid loss: 0.313 | Valid accuracy: 0.870\n",
      "Epoch 7/25 | Train loss: 0.307 | Train accuracy: 0.875 | Valid loss: 0.319 | Valid accuracy: 0.866\n",
      "Epoch 8/25 | Train loss: 0.309 | Train accuracy: 0.877 | Valid loss: 0.318 | Valid accuracy: 0.868\n",
      "Epoch 9/25 | Train loss: 0.312 | Train accuracy: 0.875 | Valid loss: 0.323 | Valid accuracy: 0.864\n",
      "Epoch 10/25 | Train loss: 0.302 | Train accuracy: 0.879 | Valid loss: 0.313 | Valid accuracy: 0.873\n",
      "Epoch 11/25 | Train loss: 0.303 | Train accuracy: 0.880 | Valid loss: 0.315 | Valid accuracy: 0.873\n",
      "Epoch 12/25 | Train loss: 0.309 | Train accuracy: 0.877 | Valid loss: 0.319 | Valid accuracy: 0.871\n",
      "Epoch 13/25 | Train loss: 0.314 | Train accuracy: 0.870 | Valid loss: 0.329 | Valid accuracy: 0.860\n",
      "Epoch 14/25 | Train loss: 0.304 | Train accuracy: 0.876 | Valid loss: 0.317 | Valid accuracy: 0.866\n",
      "Epoch 15/25 | Train loss: 0.304 | Train accuracy: 0.880 | Valid loss: 0.319 | Valid accuracy: 0.871\n",
      "Epoch 16/25 | Train loss: 0.308 | Train accuracy: 0.876 | Valid loss: 0.319 | Valid accuracy: 0.866\n",
      "Epoch 17/25 | Train loss: 0.313 | Train accuracy: 0.876 | Valid loss: 0.324 | Valid accuracy: 0.870\n",
      "Epoch 18/25 | Train loss: 0.295 | Train accuracy: 0.883 | Valid loss: 0.303 | Valid accuracy: 0.877\n",
      "Epoch 19/25 | Train loss: 0.301 | Train accuracy: 0.883 | Valid loss: 0.311 | Valid accuracy: 0.877\n",
      "Epoch 20/25 | Train loss: 0.313 | Train accuracy: 0.865 | Valid loss: 0.328 | Valid accuracy: 0.851\n",
      "Epoch 21/25 | Train loss: 0.299 | Train accuracy: 0.880 | Valid loss: 0.313 | Valid accuracy: 0.871\n",
      "Epoch 22/25 | Train loss: 0.305 | Train accuracy: 0.883 | Valid loss: 0.316 | Valid accuracy: 0.873\n",
      "Epoch 23/25 | Train loss: 0.301 | Train accuracy: 0.882 | Valid loss: 0.313 | Valid accuracy: 0.877\n",
      "Epoch 24/25 | Train loss: 0.303 | Train accuracy: 0.882 | Valid loss: 0.312 | Valid accuracy: 0.876\n",
      "Epoch 25/25 | Train loss: 0.301 | Train accuracy: 0.883 | Valid loss: 0.310 | Valid accuracy: 0.876\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Define device (GPU if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Store training history\n",
    "train_loss_history = []\n",
    "valid_loss_history = []\n",
    "train_accuracy_history = []\n",
    "valid_accuracy_history = []\n",
    "\n",
    "# Number of epochs\n",
    "num_epochs = 25\n",
    "\n",
    "def get_accuracy(preds, labels):\n",
    "    \"\"\"Calculate accuracy given model predictions and actual labels.\"\"\"\n",
    "    preds = (preds >= 0.5).float()  # Convert to binary values (0 or 1)\n",
    "    return (preds == labels).sum().item() / labels.size(0)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    for i, (X_batch, y_batch) in enumerate(train_loader):\n",
    "\n",
    "        # Move data to device\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        y_pred = model(X_batch).squeeze()\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "\n",
    "    # Calculate accuracy & loss for training and validation\n",
    "    train_loss = 0\n",
    "    valid_loss = 0\n",
    "    train_accuracy = 0\n",
    "    valid_accuracy = 0\n",
    "\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            y_pred = model(X_batch).squeeze()\n",
    "            train_loss += criterion(y_pred, y_batch).item()\n",
    "            train_accuracy += get_accuracy(y_pred, y_batch)\n",
    "\n",
    "        train_loss_history.append(train_loss / len(train_loader))\n",
    "        train_accuracy_history.append(train_accuracy / len(train_loader))\n",
    "\n",
    "        for X_batch, y_batch in val_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "            y_pred = model(X_batch).squeeze()\n",
    "            valid_loss += criterion(y_pred, y_batch).item()\n",
    "            valid_accuracy += get_accuracy(y_pred, y_batch)\n",
    "\n",
    "        valid_loss_history.append(valid_loss / len(val_loader))\n",
    "        valid_accuracy_history.append(valid_accuracy / len(val_loader))\n",
    "\n",
    "    # Print epoch summary\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | \"\n",
    "          f\"Train loss: {train_loss/len(train_loader):.3f} | \"\n",
    "          f\"Train accuracy: {train_accuracy/len(train_loader):.3f} | \"\n",
    "          f\"Valid loss: {valid_loss/len(val_loader):.3f} | \"\n",
    "          f\"Valid accuracy: {valid_accuracy/len(val_loader):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation accuracy\n",
    "plt.plot(train_accuracy_history)\n",
    "plt.plot(valid_accuracy_history)\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation accuracy\n",
    "plt.plot(train_loss_history)\n",
    "plt.plot(valid_loss_history)\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Initialize variables for metrics\n",
    "test_loss = 0.0\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "# No need to track gradients during evaluation\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        y_pred = model(X_batch).squeeze()\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(y_pred, y_batch)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        # Convert predictions to binary (0 or 1)\n",
    "        predicted = (y_pred >= 0.5).float()\n",
    "\n",
    "        # Store predictions and labels for metrics calculation\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(y_batch.cpu().numpy())\n",
    "\n",
    "# Compute average test loss\n",
    "avg_test_loss = test_loss / len(test_loader)\n",
    "\n",
    "# Compute classification metrics\n",
    "test_accuracy = accuracy_score(all_labels, all_preds)\n",
    "test_precision = precision_score(all_labels, all_preds)\n",
    "test_recall = recall_score(all_labels, all_preds)\n",
    "test_f1 = f1_score(all_labels, all_preds)\n",
    "\n",
    "# Print results\n",
    "print(f\"Test Loss: {avg_test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test Precision: {test_precision:.4f}\")\n",
    "print(f\"Test Recall: {test_recall:.4f}\")\n",
    "print(f\"Test F1 Score: {test_f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
